{"cells":[{"cell_type":"markdown","metadata":{"id":"SHVjddlS-moY"},"source":["# RNN - LSTM without any Libraries.......\n","![title](RNN-LSTM.png)"]},{"cell_type":"markdown","metadata":{"id":"TzjRxGmo-mob"},"source":["## Recurrent Neural Network"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"go-fOJu7-moc","executionInfo":{"status":"ok","timestamp":1699414316901,"user_tz":-420,"elapsed":10,"user":{"displayName":"Tánh Lý Văn","userId":"05266482744684150681"}}},"outputs":[],"source":["import numpy as np\n","\n","class RecurrentNeuralNetwork:\n","\n","    def __init__ (self, input, output, recurrences, expected_output, learning_rate):\n","        #initial input\n","        self.x = np.zeros(input)\n","        #input size\n","        self.input = input\n","        #expected output\n","        self.y = np.zeros(output)\n","        #output size\n","        self.output = output\n","        #weight matrix\n","        self.w = np.random.random((output, output))\n","        #matrix used in RMSprop in order to decay the learning rate\n","        self.G = np.zeros_like(self.w)\n","        #length of the recurrent network\n","        self.recurrences = recurrences\n","        #learning rate\n","        self.learning_rate = learning_rate\n","        #array for storing inputs\n","        self.ia = np.zeros((recurrences+1,input))\n","        #array for storing cell states\n","        self.ca = np.zeros((recurrences+1,output))\n","        #array for storing outputs\n","        self.oa = np.zeros((recurrences+1,output))\n","        #array for storing hidden states\n","        self.ha = np.zeros((recurrences+1,output))\n","        #forget gate\n","        self.af = np.zeros((recurrences+1,output))\n","        #input gate\n","        self.ai = np.zeros((recurrences+1,output))\n","        #cell state\n","        self.ac = np.zeros((recurrences+1,output))\n","        #output gate\n","        self.ao = np.zeros((recurrences+1,output))\n","        #array of expected output values\n","        self.expected_output = np.vstack((np.zeros(expected_output.shape[0]), expected_output.T))\n","        #declare LSTM cell\n","        self.LSTM = LSTM(input, output, recurrences, learning_rate)\n","\n","    #sigmoid activation function\n","    def sigmoid(self, x):\n","        return 1 / (1 + np.exp(-x))\n","\n","    #derivative of sigmoid\n","    def dsigmoid(self, x):\n","        return self.sigmoid(x) * (1 - self.sigmoid(x))\n","\n","    #Forward Propagation\n","    def forwardProp(self):\n","        for i in range(1, self.recurrences+1):\n","            self.LSTM.x = np.hstack((self.ha[i-1], self.x))\n","            cs, hs, f, c, o = self.LSTM.forwardProp()\n","            #store cell state from the forward propagation\n","            self.ca[i] = cs #cell state\n","            self.ha[i] = hs #hidden state\n","            self.af[i] = f #forget state\n","            self.ai[i] = inp #inpute gate\n","            self.ac[i] = c #cell state\n","            self.ao[i] = o #output gate\n","            self.oa[i] = self.sigmoid(np.dot(self.w, hs)) #activate the weight*input\n","            self.x = self.expected_output[i-1]\n","        return self.oa\n","\n","    # Back propagation\n","    def backProp(self):\n","        totalError = 0\n","        #cell state\n","        dfcs = np.zeros(self.output)\n","        #hidden state,\n","        dfhs = np.zeros(self.output)\n","        #weight matrix\n","        tu = np.zeros((self.output,self.output))\n","        #forget gate\n","        tfu = np.zeros((self.output, self.input+self.output))\n","        #input gate\n","        tiu = np.zeros((self.output, self.input+self.output))\n","        #cell unit\n","        tcu = np.zeros((self.output, self.input+self.output))\n","        #output gate\n","        tou = np.zeros((self.output, self.input+self.output))\n","        for i in range(self.recurrences, -1, -1):\n","            error = self.oa[i] - self.expected_output[i]\n","            tu += np.dot(np.atleast_2d(error * self.dsigmoid(self.oa[i])), np.atleast_2d(self.ha[i]).T)\n","            error = np.dot(error, self.w)\n","            self.LSTM.x = np.hstack((self.ha[i-1], self.ia[i]))\n","            self.LSTM.cs = self.ca[i]\n","            fu, iu, cu, ou, dfcs, dfhs = self.LSTM.backProp(error, self.ca[i-1], self.af[i], self.ai[i], self.ac[i], self.ao[i], dfcs, dfhs)\n","            totalError += np.sum(error)\n","            #forget gate\n","            tfu += fu\n","            #input gate\n","            tiu += iu\n","            #cell state\n","            tcu += cu\n","            #output gate\n","            tou += ou\n","        self.LSTM.update(tfu/self.recurrences, tiu/self.recurrences, tcu/self.recurrences, tou/self.recurrences)\n","        self.update(tu/self.recurrences)\n","        return totalError\n","\n","    def update(self, u):\n","        self.G = 0.95 * self.G + 0.1 * u**2\n","        self.w -= self.learning_rate/np.sqrt(self.G + 1e-8) * u\n","        return\n","\n","    def sample(self):\n","        for i in range(1, self.recurrences+1):\n","            self.LSTM.x = np.hstack((self.ha[i-1], self.x))\n","            cs, hs, f, inp, c, o = self.LSTM.forwardProp()\n","            maxI = np.argmax(self.x)\n","            self.x = np.zeros_like(self.x)\n","            self.x[maxI] = 1\n","            self.ia[i] = self.x\n","            #store cell states\n","            self.ca[i] = cs\n","            #store hidden state\n","            self.ha[i] = hs\n","            #forget gate\n","            self.af[i] = f\n","            #input gate\n","            self.ai[i] = inp\n","            #cell state\n","            self.ac[i] = c\n","            #output gate\n","            self.ao[i] = o\n","            self.oa[i] = self.sigmoid(np.dot(self.w, hs))\n","            maxI = np.argmax(self.oa[i])\n","            newX = np.zeros_like(self.x)\n","            newX[maxI] = 1\n","            self.x = newX\n","\n","        return self.oa\n"]},{"cell_type":"markdown","metadata":{"id":"F3a4My4h-mof"},"source":["## Long short-term memory"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"0V6XOLvH-mog","executionInfo":{"status":"ok","timestamp":1699414544667,"user_tz":-420,"elapsed":368,"user":{"displayName":"Tánh Lý Văn","userId":"05266482744684150681"}}},"outputs":[],"source":["class LSTM:\n","    # LSTM cell (input, output, amount of recurrence, learning rate)\n","    def __init__ (self, input, output, recurrences, learning_rate):\n","        #input size\n","        self.x = np.zeros(input+output)\n","        #input size\n","        self.input = input + output\n","        #output\n","        self.y = np.zeros(output)\n","        #output size\n","        self.output = output\n","        #cell state intialized as size of prediction\n","        self.cs = np.zeros(output)\n","        #how often to perform recurrence\n","        self.recurrences = recurrences\n","        #balance the rate of training (learning rate)\n","        self.learning_rate = learning_rate\n","        #init weight matrices for our gates\n","        #forget gate\n","        self.f = np.random.random((output, input+output))\n","        #input gate\n","        self.i = np.random.random((output, input+output))\n","        #cell state\n","        self.c = np.random.random((output, input+output))\n","        #output gate\n","        self.o = np.random.random((output, input+output))\n","        #forget gate gradient\n","        self.Gf = np.zeros_like(self.f)\n","        #input gate gradient\n","        self.Gi = np.zeros_like(self.i)\n","        #cell state gradient\n","        self.Gc = np.zeros_like(self.c)\n","        #output gate gradient\n","        self.Go = np.zeros_like(self.o)\n","\n","\n","    def sigmoid(self, x):\n","        return 1 / (1 + np.exp(-x))\n","\n","    def dsigmoid(self, x):\n","        return self.sigmoid(x) * (1 - self.sigmoid(x))\n","\n","\n","    def tangent(self, x):\n","        return np.tanh(x)\n","\n","\n","    def dtangent(self, x):\n","        return 1 - np.tanh(x)**2\n","\n","    def forwardProp(self):\n","        f = self.sigmoid(np.dot(self.f, self.x))\n","        self.cs *= f\n","        i = self.sigmoid(np.dot(self.i, self.x))\n","        c = self.tangent(np.dot(self.c, self.x))\n","        self.cs += i * c\n","        o = self.sigmoid(np.dot(self.o, self.x))\n","        self.y = o * self.tangent(self.cs)\n","        return self.cs, self.y, f, i, c, o\n","\n","\n","    def backProp(self, e, pcs, f, i, c, o, dfcs, dfhs):\n","\n","        e = np.clip(e + dfhs, -6, 6)\n","\n","        do = self.tangent(self.cs) * e\n","\n","        ou = np.dot(np.atleast_2d(do * self.dtangent(o)).T, np.atleast_2d(self.x))\n","\n","        dcs = np.clip(e * o * self.dtangent(self.cs) + dfcs, -6, 6)\n","\n","        dc = dcs * i\n","\n","        cu = np.dot(np.atleast_2d(dc * self.dtangent(c)).T, np.atleast_2d(self.x))\n","\n","        di = dcs * c\n","\n","        iu = np.dot(np.atleast_2d(di * self.dsigmoid(i)).T, np.atleast_2d(self.x))\n","\n","        df = dcs * pcs\n","\n","        fu = np.dot(np.atleast_2d(df * self.dsigmoid(f)).T, np.atleast_2d(self.x))\n","\n","        dpcs = dcs * f\n","\n","        dphs = np.dot(dc, self.c)[:self.output] + np.dot(do, self.o)[:self.output] + np.dot(di, self.i)[:self.output] + np.dot(df, self.f)[:self.output]\n","\n","        return fu, iu, cu, ou, dpcs, dphs\n","\n","    def update(self, fu, iu, cu, ou):\n","        #Update forget, input, cell, and output gradients\n","        self.Gf = 0.9 * self.Gf + 0.1 * fu**2\n","        self.Gi = 0.9 * self.Gi + 0.1 * iu**2\n","        self.Gc = 0.9 * self.Gc + 0.1 * cu**2\n","        self.Go = 0.9 * self.Go + 0.1 * ou**2\n","\n","        #Update our gates using our gradients\n","        self.f -= self.learning_rate/np.sqrt(self.Gf + 1e-8) * fu\n","        self.i -= self.learning_rate/np.sqrt(self.Gi + 1e-8) * iu\n","        self.c -= self.learning_rate/np.sqrt(self.Gc + 1e-8) * cu\n","        self.o -= self.learning_rate/np.sqrt(self.Go + 1e-8) * ou\n","        return"]},{"cell_type":"markdown","metadata":{"id":"1JeBLMBI-mog"},"source":["## Dataset Preprocessing"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":366},"id":"BetbQt1s-moh","executionInfo":{"status":"error","timestamp":1699416464829,"user_tz":-420,"elapsed":533,"user":{"displayName":"Tánh Lý Văn","userId":"05266482744684150681"}},"outputId":"12cfa928-9607-495e-f725-04ef19dd715e"},"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-0b9f7f2fb720>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0mdata_dir\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'input.txt'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0mview_sentence_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m81\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-7-0b9f7f2fb720>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \"\"\"\n\u001b[1;32m      9\u001b[0m     \u001b[0minput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'input.txt'"]}],"source":["import os\n","import pickle\n","\n","\n","def load_data(path):\n","    \"\"\"\n","    Load Dataset from File\n","    \"\"\"\n","    input_file = os.path.join(path)\n","    with open(input_file, \"r\") as f:\n","        data = f.read()\n","\n","    return data\n","\n","\n","def preprocess_and_save_data(dataset_path, token_lookup, create_lookup_tables):\n","    \"\"\"\n","    Preprocess Text Data\n","    \"\"\"\n","    text = load_data(dataset_path)\n","\n","    # Ignore notice, since we don't use it for analysing the data\n","    text = text[81:]\n","\n","    token_dict = token_lookup()\n","    for key, token in token_dict.items():\n","        text = text.replace(key, ' {} '.format(token))\n","\n","    text = text.lower()\n","    text = text.split()\n","\n","    vocab_to_int, int_to_vocab = create_lookup_tables(text)\n","    int_text = [vocab_to_int[word] for word in text]\n","    pickle.dump((int_text, vocab_to_int, int_to_vocab, token_dict), open('preprocess.p', 'wb'))\n","\n","\n","def load_preprocess():\n","    \"\"\"\n","    Load the Preprocessed Training data and return them in batches of <batch_size> or less\n","    \"\"\"\n","    return pickle.load(open('preprocess.p', mode='rb'))\n","\n","\n","def save_params(params):\n","    \"\"\"\n","    Save parameters to file\n","    \"\"\"\n","    pickle.dump(params, open('params.p', 'wb'))\n","\n","\n","def load_params():\n","    \"\"\"\n","    Load parameters from file\n","    \"\"\"\n","    return pickle.load(open('params.p', mode='rb'))\n","\n","data_dir = 'input.txt'\n","text = load_data(data_dir)\n","view_sentence_range = (0, 50)\n","text = text[81:]\n","\n","\n","print('Dataset Stats')\n","print('Roughly the number of unique words: {}'.format(len({word: None for word in text.split()})))\n","scenes = text.split('\\n\\n')\n","print('Number of scenes: {}'.format(len(scenes)))\n","sentence_count_scene = [scene.count('\\n') for scene in scenes]\n","print('Average number of sentences in each scene: {}'.format(np.average(sentence_count_scene)))\n","\n","sentences = [sentence for scene in scenes for sentence in scene.split('\\n')]\n","print('Number of lines: {}'.format(len(sentences)))\n","word_count_sentence = [len(sentence.split()) for sentence in sentences]\n","print('Average number of words in each line: {}'.format(np.average(word_count_sentence)))\n","\n","print()\n","print('The sentences {} to {}:'.format(*view_sentence_range))\n","print('\\n'.join(text.split('\\n')[view_sentence_range[0]:view_sentence_range[1]]))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6yps4ed6-moi"},"outputs":[],"source":["def create_lookup_tables(text):\n","    vocab = set(text)\n","    vocab_to_int = {w: i for i, w in enumerate(vocab)}\n","    int_to_vocab = dict(enumerate(vocab))\n","    return (vocab_to_int, int_to_vocab)\n","\n","def token_lookup():\n","    return {'.':'||period||',\n","            ',':'||comma||',\n","            '\"':'||double_quotes||',\n","            ';':'||semicolon||',\n","            '!':'||exclamation_mark||',\n","            '?':'||question_mark||',\n","            '(':'||left_paren||',\n","            ')':'||right_paren||',\n","            '--':'||dash||',\n","            '\\n':'||newline||'}\n","\n","helper.preprocess_and_save_data(data_dir, token_lookup, create_lookup_tables)"]},{"cell_type":"markdown","metadata":{"id":"XJCq9OgJ-moj"},"source":["# Model Inititialization And Training"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"Dfe92bLs-mok"},"outputs":[],"source":["print(\"Initialize Hyperparameters\")\n","iterations = 10000\n","learningRate = 0.001\n","print(\"Reading Input/Output data from disk\")\n","returnData, numCategories, expectedOutput, outputSize, data = read_text_file()\n","\n","print(\"Reading from disk done. Proceeding with training.\")\n","#Initialize the RNN using our hyperparameters and data\n","RNN = RecurrentNeuralNetwork(numCategories, numCategories, outputSize, expectedOutput, learningRate)\n","\n","#training time!\n","for i in range(1, iterations):\n","    #Predict the next word of each word\n","    RNN.forwardProp()\n","    #update all our weights using our error\n","    error = RNN.backProp()\n","    #For a given error threshold\n","    print(\"Reporting error on iteration \", i, \": \", error)\n","    if error > -10 and error < 10 or i % 10 == 0:\n","        #We provide a seed word\n","        seed = np.zeros_like(RNN.x)\n","        maxI = np.argmax(np.random.random(RNN.x.shape))\n","        seed[maxI] = 1\n","        RNN.x = seed\n","        #and predict the upcoming one\n","        output = RNN.sample()\n","        print(output)\n","        #finally, we store it to disk\n","        export_to_textfile(output, data)\n","        print(\"Done Writing\")\n","print(\"Train/Prediction routine complete.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"itfx22du-mok"},"outputs":[],"source":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.5.5"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}